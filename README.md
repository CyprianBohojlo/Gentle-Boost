# Gentle-Boost

In this university project, I manually implement from scratch a Gentle Boost algorithm using Numpy library only. Gentle Boost is a variant of AdaBoost that’s designed to be more stable and less sensitive to noisy data or outliers. 
<img width="826" height="352" alt="gentle boost" src="https://github.com/user-attachments/assets/bac003e5-8191-4a15-be88-177de29f9a5b" />


Finally, I test the algorithm on USPS digit recogniction data. The dataset consits of many variants of handwritten digits such as the ones presented below. The algorithm's goal is to recognize the digit written and classify it correctly. 
<img width="1163" height="492" alt="digits" src="https://github.com/user-attachments/assets/e6e7166d-fa78-432e-ac7b-f240cf842e6c" />

## References

1. **Chapman Siu** (2023). *Online GentleAdaBoost – Technical Report*. University of Technology Sydney.  
   [Read the full report on arXiv](https://arxiv.org/pdf/2308.14004)

2. **Trevor Hastie, Robert Tibshirani, Jerome Friedman** (2001). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. Springer. Chapter 10: Boosting and Additive Trees.  
   [View the book on Springer](https://link.springer.com/book/10.1007/978-0-387-84858-7)  
   [Read Chapter 10 via ResearchGate](https://www.researchgate.net/profile/Trevor-Hastie/publication/226862591_Boosting_and_Additive_Trees/links/0c960521b946fa03bd000000/Boosting-and-Additive-Trees.pdf)

